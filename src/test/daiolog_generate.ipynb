{
 "cells": [
  {
   "cell_type": "code",
   "id": "5af52ce4cbc6b413",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-31T14:06:50.043445Z",
     "start_time": "2024-08-31T14:06:42.677880Z"
    }
   },
   "source": [
    "from paddlenlp import Taskflow\n",
    "\n",
    "summarizer = Taskflow(\"text_summarization\", batch_size=16)\n",
    "# 单条输入\n",
    "summarizer('为深入贯彻落实习近平总书记关于民营经济发展系列重要讲话精神和全省民营经济健康发展大会精神，进一步营造良好营商环境、支持民营经济健康发展，8月24日至29日，由省委组织部主办、省市场监管局承办的全省培育壮大民营经济专题研讨班在浙江省委党校举办。。全省各市（州）分管领导、部分市（州）民营办负责人、省民营经济和中小企业发展领导小组部分成员单位、部分省属高等院校、有关金融机构分管领导和民营企业家代表60人聚集杭州，深入探索“浙江现象”，研究“浙江模式”，学习“浙江精神”，研讨交流营造我省良好营商环境、支持民营经济健康发展的方法举措。。此次专题研讨班是一次深化落实中央和省委、省政府支持民营经济发展政策措施的学习之旅。研讨班紧紧围绕着浙江民营经济发展轨迹，从《“八八战略”与浙江发展》、《浙江经济创新发展与浙江精神》等课程辅导，到杭州（滨江）国家级高新技术开区物联网产业园区、杭州市富阳区行政服务中心学习考察，再到阿里巴巴蚂蚁金服Z空间、宇视科技参观交流，一段段生动的故事、一个个鲜活的事例、一家家蓬勃的企业，无时不在展示着浙江民营经济发展的活力与动力，多维度、多角度解读浙江省民营经济发展历程和宝贵经验，为促进我省民营经济高质量发展提供借鉴并启发思想，让学员受益匪浅、收获颇丰、感受良多。。随着进入最后的分组讨论阶段，各位学员踊跃发言、深入探讨，畅谈着此次培训的收获与心得体会。如何进一步促进我省民营经济健康发展，思想得到了碰撞、思路得到了明晰，信心得到了坚定。。中共遂宁市委常委、市委统战部部长杨军认为浙江省把中央精神和浙江实际紧密结合，解放思想，开拓创新，在制度创新、社会发展、基层民主、文化建设、党的建设等方面也创造了诸多经验，形成了经济社会发展的浙江模式，值得学习与深思。。成都理工大学党委常委、副校长郭朝辉认为优质人才是创新发展的不竭动力，高校将进一步转变观念、解放思想，加大与政府、企业合作力度，为四川民营经济发展培育更多具有企业家精神、工匠精神的开放性人才。。宜宾市人民政府副市长王力平认为“最多跑一次”改革作为浙江全面深化改革的重要突破口、“放管服”改革的精准抓手，经过探索实施，已经形成比较成熟的制度规范与标准体系，改革红利不断释放，积累了丰富的实践经验，对四川深化改革和营商环境建设具有积极的借鉴意义。。大道至简，实干为要。通过举办这次专题研讨班，对标浙江，映照自己，广大学员表示将进一步解放思想、敢于探索，求真务实、勇于创新，并在实际工作中认真应用研讨成果，不断开拓工作思路，敢于担当，积极作为，努力为推动我省民营经济高质量发展、推动治蜀兴川再上新台阶做出新的更大的贡献。')\n",
    "# 输出：['万科喊话中国房地产进入“黑铁时代”']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-08-31 22:06:42,685] [    INFO]\u001B[0m - We are using <class 'paddlenlp.transformers.pegasus.tokenizer.PegasusChineseTokenizer'> to load 'PaddlePaddle/Randeng-Pegasus-523M-Summary-Chinese-SSTIA'.\u001B[0m\n",
      "\u001B[32m[2024-08-31 22:06:42,808] [    INFO]\u001B[0m - We are using <class 'paddlenlp.transformers.pegasus.modeling.PegasusForConditionalGeneration'> to load 'PaddlePaddle/Randeng-Pegasus-523M-Summary-Chinese-SSTIA'.\u001B[0m\n",
      "\u001B[32m[2024-08-31 22:06:42,810] [    INFO]\u001B[0m - Loading configuration file /root/.paddlenlp/models/PaddlePaddle/Randeng-Pegasus-523M-Summary-Chinese-SSTIA/model_config.json\u001B[0m\n",
      "\u001B[32m[2024-08-31 22:06:42,812] [    INFO]\u001B[0m - Loading weights file from cache at /root/.paddlenlp/models/PaddlePaddle/Randeng-Pegasus-523M-Summary-Chinese-SSTIA/model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-08-31 22:06:45,243] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[33m[2024-08-31 22:06:49,700] [ WARNING]\u001B[0m - Some weights of the model checkpoint at PaddlePaddle/Randeng-Pegasus-523M-Summary-Chinese-SSTIA were not used when initializing PegasusForConditionalGeneration: ['pegasus.decoder.decoder.layers.12.cross_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.12.cross_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.12.cross_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.12.cross_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.12.cross_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.12.cross_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.12.cross_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.12.cross_attn.v_proj.weight', 'pegasus.decoder.decoder.layers.12.linear1.bias', 'pegasus.decoder.decoder.layers.12.linear1.weight', 'pegasus.decoder.decoder.layers.12.linear2.bias', 'pegasus.decoder.decoder.layers.12.linear2.weight', 'pegasus.decoder.decoder.layers.12.norm1.bias', 'pegasus.decoder.decoder.layers.12.norm1.weight', 'pegasus.decoder.decoder.layers.12.norm2.bias', 'pegasus.decoder.decoder.layers.12.norm2.weight', 'pegasus.decoder.decoder.layers.12.norm3.bias', 'pegasus.decoder.decoder.layers.12.norm3.weight', 'pegasus.decoder.decoder.layers.12.self_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.12.self_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.12.self_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.12.self_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.12.self_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.12.self_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.12.self_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.12.self_attn.v_proj.weight', 'pegasus.decoder.decoder.layers.13.cross_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.13.cross_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.13.cross_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.13.cross_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.13.cross_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.13.cross_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.13.cross_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.13.cross_attn.v_proj.weight', 'pegasus.decoder.decoder.layers.13.linear1.bias', 'pegasus.decoder.decoder.layers.13.linear1.weight', 'pegasus.decoder.decoder.layers.13.linear2.bias', 'pegasus.decoder.decoder.layers.13.linear2.weight', 'pegasus.decoder.decoder.layers.13.norm1.bias', 'pegasus.decoder.decoder.layers.13.norm1.weight', 'pegasus.decoder.decoder.layers.13.norm2.bias', 'pegasus.decoder.decoder.layers.13.norm2.weight', 'pegasus.decoder.decoder.layers.13.norm3.bias', 'pegasus.decoder.decoder.layers.13.norm3.weight', 'pegasus.decoder.decoder.layers.13.self_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.13.self_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.13.self_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.13.self_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.13.self_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.13.self_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.13.self_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.13.self_attn.v_proj.weight', 'pegasus.decoder.decoder.layers.14.cross_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.14.cross_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.14.cross_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.14.cross_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.14.cross_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.14.cross_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.14.cross_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.14.cross_attn.v_proj.weight', 'pegasus.decoder.decoder.layers.14.linear1.bias', 'pegasus.decoder.decoder.layers.14.linear1.weight', 'pegasus.decoder.decoder.layers.14.linear2.bias', 'pegasus.decoder.decoder.layers.14.linear2.weight', 'pegasus.decoder.decoder.layers.14.norm1.bias', 'pegasus.decoder.decoder.layers.14.norm1.weight', 'pegasus.decoder.decoder.layers.14.norm2.bias', 'pegasus.decoder.decoder.layers.14.norm2.weight', 'pegasus.decoder.decoder.layers.14.norm3.bias', 'pegasus.decoder.decoder.layers.14.norm3.weight', 'pegasus.decoder.decoder.layers.14.self_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.14.self_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.14.self_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.14.self_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.14.self_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.14.self_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.14.self_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.14.self_attn.v_proj.weight', 'pegasus.decoder.decoder.layers.15.cross_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.15.cross_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.15.cross_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.15.cross_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.15.cross_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.15.cross_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.15.cross_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.15.cross_attn.v_proj.weight', 'pegasus.decoder.decoder.layers.15.linear1.bias', 'pegasus.decoder.decoder.layers.15.linear1.weight', 'pegasus.decoder.decoder.layers.15.linear2.bias', 'pegasus.decoder.decoder.layers.15.linear2.weight', 'pegasus.decoder.decoder.layers.15.norm1.bias', 'pegasus.decoder.decoder.layers.15.norm1.weight', 'pegasus.decoder.decoder.layers.15.norm2.bias', 'pegasus.decoder.decoder.layers.15.norm2.weight', 'pegasus.decoder.decoder.layers.15.norm3.bias', 'pegasus.decoder.decoder.layers.15.norm3.weight', 'pegasus.decoder.decoder.layers.15.self_attn.k_proj.bias', 'pegasus.decoder.decoder.layers.15.self_attn.k_proj.weight', 'pegasus.decoder.decoder.layers.15.self_attn.out_proj.bias', 'pegasus.decoder.decoder.layers.15.self_attn.out_proj.weight', 'pegasus.decoder.decoder.layers.15.self_attn.q_proj.bias', 'pegasus.decoder.decoder.layers.15.self_attn.q_proj.weight', 'pegasus.decoder.decoder.layers.15.self_attn.v_proj.bias', 'pegasus.decoder.decoder.layers.15.self_attn.v_proj.weight', 'pegasus.encoder.encoder.layers.12.linear1.bias', 'pegasus.encoder.encoder.layers.12.linear1.weight', 'pegasus.encoder.encoder.layers.12.linear2.bias', 'pegasus.encoder.encoder.layers.12.linear2.weight', 'pegasus.encoder.encoder.layers.12.norm1.bias', 'pegasus.encoder.encoder.layers.12.norm1.weight', 'pegasus.encoder.encoder.layers.12.norm2.bias', 'pegasus.encoder.encoder.layers.12.norm2.weight', 'pegasus.encoder.encoder.layers.12.self_attn.k_proj.bias', 'pegasus.encoder.encoder.layers.12.self_attn.k_proj.weight', 'pegasus.encoder.encoder.layers.12.self_attn.out_proj.bias', 'pegasus.encoder.encoder.layers.12.self_attn.out_proj.weight', 'pegasus.encoder.encoder.layers.12.self_attn.q_proj.bias', 'pegasus.encoder.encoder.layers.12.self_attn.q_proj.weight', 'pegasus.encoder.encoder.layers.12.self_attn.v_proj.bias', 'pegasus.encoder.encoder.layers.12.self_attn.v_proj.weight', 'pegasus.encoder.encoder.layers.13.linear1.bias', 'pegasus.encoder.encoder.layers.13.linear1.weight', 'pegasus.encoder.encoder.layers.13.linear2.bias', 'pegasus.encoder.encoder.layers.13.linear2.weight', 'pegasus.encoder.encoder.layers.13.norm1.bias', 'pegasus.encoder.encoder.layers.13.norm1.weight', 'pegasus.encoder.encoder.layers.13.norm2.bias', 'pegasus.encoder.encoder.layers.13.norm2.weight', 'pegasus.encoder.encoder.layers.13.self_attn.k_proj.bias', 'pegasus.encoder.encoder.layers.13.self_attn.k_proj.weight', 'pegasus.encoder.encoder.layers.13.self_attn.out_proj.bias', 'pegasus.encoder.encoder.layers.13.self_attn.out_proj.weight', 'pegasus.encoder.encoder.layers.13.self_attn.q_proj.bias', 'pegasus.encoder.encoder.layers.13.self_attn.q_proj.weight', 'pegasus.encoder.encoder.layers.13.self_attn.v_proj.bias', 'pegasus.encoder.encoder.layers.13.self_attn.v_proj.weight', 'pegasus.encoder.encoder.layers.14.linear1.bias', 'pegasus.encoder.encoder.layers.14.linear1.weight', 'pegasus.encoder.encoder.layers.14.linear2.bias', 'pegasus.encoder.encoder.layers.14.linear2.weight', 'pegasus.encoder.encoder.layers.14.norm1.bias', 'pegasus.encoder.encoder.layers.14.norm1.weight', 'pegasus.encoder.encoder.layers.14.norm2.bias', 'pegasus.encoder.encoder.layers.14.norm2.weight', 'pegasus.encoder.encoder.layers.14.self_attn.k_proj.bias', 'pegasus.encoder.encoder.layers.14.self_attn.k_proj.weight', 'pegasus.encoder.encoder.layers.14.self_attn.out_proj.bias', 'pegasus.encoder.encoder.layers.14.self_attn.out_proj.weight', 'pegasus.encoder.encoder.layers.14.self_attn.q_proj.bias', 'pegasus.encoder.encoder.layers.14.self_attn.q_proj.weight', 'pegasus.encoder.encoder.layers.14.self_attn.v_proj.bias', 'pegasus.encoder.encoder.layers.14.self_attn.v_proj.weight', 'pegasus.encoder.encoder.layers.15.linear1.bias', 'pegasus.encoder.encoder.layers.15.linear1.weight', 'pegasus.encoder.encoder.layers.15.linear2.bias', 'pegasus.encoder.encoder.layers.15.linear2.weight', 'pegasus.encoder.encoder.layers.15.norm1.bias', 'pegasus.encoder.encoder.layers.15.norm1.weight', 'pegasus.encoder.encoder.layers.15.norm2.bias', 'pegasus.encoder.encoder.layers.15.norm2.weight', 'pegasus.encoder.encoder.layers.15.self_attn.k_proj.bias', 'pegasus.encoder.encoder.layers.15.self_attn.k_proj.weight', 'pegasus.encoder.encoder.layers.15.self_attn.out_proj.bias', 'pegasus.encoder.encoder.layers.15.self_attn.out_proj.weight', 'pegasus.encoder.encoder.layers.15.self_attn.q_proj.bias', 'pegasus.encoder.encoder.layers.15.self_attn.q_proj.weight', 'pegasus.encoder.encoder.layers.15.self_attn.v_proj.bias', 'pegasus.encoder.encoder.layers.15.self_attn.v_proj.weight']\n",
      "- This IS expected if you are initializing PegasusForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PegasusForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[32m[2024-08-31 22:06:49,702] [    INFO]\u001B[0m - All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at PaddlePaddle/Randeng-Pegasus-523M-Summary-Chinese-SSTIA.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\u001B[0m\n",
      "\u001B[32m[2024-08-31 22:06:49,749] [    INFO]\u001B[0m - Generation config file not found, using a generation config created from the model config.\u001B[0m\n",
      "\u001B[33m[2024-08-31 22:06:49,836] [ WARNING]\u001B[0m - `max_length` will be deprecated in future releases, use `max_new_tokens` instead.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:05:44.192841Z",
     "start_time": "2024-08-31T14:05:43.869834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 多条输入\n",
    "summarizer([\n",
    "  '据悉，2022年教育部将围绕“巩固提高、深化落实、创新突破”三个关键词展开工作。要进一步强化学校教育主阵地作用，继续把落实“双减”作为学校工作的重中之重，重点从提高作业设计水平、提高课后服务水平、提高课堂教学水平、提高均衡发展水平四个方面持续巩固提高学校“双减”工作水平。',\n",
    "  '党参有降血脂，降血压的作用，可以彻底消除血液中的垃圾，从而对冠心病以及心血管疾病的患者都有一定的稳定预防工作作用，因此平时口服党参能远离三高的危害。另外党参除了益气养血，降低中枢神经作用，调整消化系统功能，健脾补肺的功能。'\n",
    "  ])\n",
    "#输出：['教育部：将从四个方面持续巩固提高学校“双减”工作水平', '党参能降低三高的危害']"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33m[2024-08-31 22:05:43,881] [ WARNING]\u001B[0m - `max_length` will be deprecated in future releases, use `max_new_tokens` instead.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '有有降血压的作用']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
